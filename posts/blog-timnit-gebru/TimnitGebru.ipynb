{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "745fb38c-5b9d-49d7-8e91-f6deb18bedfe",
   "metadata": {},
   "source": [
    "# Learning from Timnit Gebru (Parts 1 and 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4d2b692-076a-4760-8970-501ccc508881",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "Dr. Timnit Gebru is a computer scientist best known for her substantial work on AI ethics and algorithmic bias. She has also done substantial work on computer vision and natural language processing. She is best known for her research highlighting the biases and limitations of facial recognition technology.\n",
    "\n",
    "She had co-founded the Ethical AI team at Google in 2018. In 2020, her work with Google came to an end due to a dispute regarding a paper on the limitations and biases of natural language processing models co-authored by her. Dr. Gebru claims that her paper was not accepted by Google's journal due to it not taking AI ethics seriously. Her alleged removal from Google was widely reported in the media as an example of large technology companies silencing voices expressing concern about the nature of their operations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "008f249e-cc8c-4bcc-b955-228f75340914",
   "metadata": {},
   "source": [
    "## Notes from the lecture\n",
    "\n",
    "Dr. Gebru is particularly concerned about how facial recognition tools are used, and how they could be used, by law enforcement agencies. Firstly, facial recognition models face data related constraints, especially among racial and ethnic minorities, and individuals that are non cisgender men. These constrains can result in poorer recognition of these minorities, putting these individuals at greater risk of being interrogated or imprisoned without cause. These tools are also less effective in recognizing cultural differences in non-white cultures, due to biases in data.\n",
    "\n",
    "She also argues that the practices used by law enforcement agencies to collect data for these purposes is highly suspect. States, such as Maryland, use extensive level surveillance programs. Law enforcement agencies have also scraped social media sites to find pictures of individuals participating in certain political activities, and have used their facial recognition models to identify these individuals. According to Dr. Gebru, these practices stifle political dissent and limit personal freedom.  \n",
    "\n",
    "Additionally, facial recognition tools might not be used by law enforcement agencies in the ways in which these tools were intended to be used. Hence, biases that are rampant in these institutions could be magnified by these technologies. These tools can also be used by authoritarian regimes to maintain control and establish a police state.\n",
    "\n",
    "Tl;dr: computer vision technologies are expected to magnify biases that already exist within our societies. To prevent this from happening, we need to be more conscious about how diverse our data is, and how are data is being collected. We also need to be conscious about biases within our models and have a sense of who it is benefiting and who it harming."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe9f6243-96c4-4809-84c3-68151e2344c6",
   "metadata": {},
   "source": [
    "## Proposed Question:\n",
    "\n",
    "The advancement of computer vision and natural langauge processing models has some obvious benefits and drawbacks. Dr. Gebru's work does a great job in identifying and studying manners in these models may magnify systemic biases experienced by racial minorities and individuals that are not cisgender men. She is also very convincing in her arguments about how authoritarian regimes may misuse these technologies. However, just as building a model may put certain people at risk, not building a model may also prevent a group of people from realizing certain benefits. How do we assess the opportunity cost of unrealized benefits with the risks posed by machine learning models within the context of ML-related regulation?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27272034-af9d-4fbc-9f3d-7b2afdaecd08",
   "metadata": {},
   "source": [
    "## Reflection on Dr. Gebru's class discussion\n",
    "\n",
    "I agree with Dr. Gebru's idea that funding for ML-related research needs to be more diversified. When most of the funding comes from the government and private corporations with certain vested interests, it is inevitable that these interests, which prioritize what is beneficial at the short term over what is beneficial over the long term.\n",
    "\n",
    "However, I am not sure if I am as pessimistic about the future of ML as Dr Gebru. In our conversation, it seemed as though Dr. Gebru was discounting the benefits that ML has brought, and can bring, to vulnerable communities. \n",
    "\n",
    "I really enjoyed Xianzhi's question about the construction of an alternative reality in which everything computer vision can be rebuilt in a manner that is beneficial for society at large in the long term. I found it somewhat surprising that, according to Dr. Gebru, in an ideal society, computer vision should not exist. It felt as though Professor Gebru was ignoring some of positive effects of computer vision. For example, it results in improved medical diagnostics and helps make the internet more accesible. Dr. Gebru, due to her years of experience in this field, may have a greater degree of pessimism associated with the effects of machine learning that might be unfathomable to me.\n",
    "\n",
    "I was also slightly disappointed by her response to my question. My question focused on the weighing the opportunity costs associated with putting restrictions on AI research. The idea behind this question is that while the research and applications of machine learning technologies are doing a lot of bad in the world, they are also doing a lot of good.  In my opinion, good that is prevented from happening is equivalent to something bad being done. I was expecting an answer that weighed the bad done by ML against the good. However, I do not think that her response to my question did this. I think that she made an argument related to path dependency which somewhat satisfied me."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "393ca18d-b7ff-4d3f-968b-eae1d6f17925",
   "metadata": {},
   "source": [
    "## Dr. Gebru's presentation at Hillcrest\n",
    "\n",
    "Dr. Gebru's discussed several intellectual movements- denoted by the umbrella term TESCREAL- that are currently involved in the study of AI ethics and AI risk minization, and argued that these movements are tied to eugenics. She suggested that some of the personalities, such as Eliezer Yudkowsky, involved in these movements are racist, problematic and poorly equipped to handle this topic. She also argues that the God Complex harbored by some in this field is problematic. She also discussed her disdain for the term \"AGI.\" She argued that this term is extremely vague and that it has effectively become a buzzword for companies such as OpenAI. She also expressed her disdain for for certain tech-evangelists, like Sam Altman who believe that machine learning will change the world for the better. She touched upon the problematic history of statistics, and how it was tied in with the development of Eugenics. In fact, Galton, a pioneering figure in modern statistics, is also one of the foremeost figures in the Eugenics movement. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d626d15-55e4-4c9c-96a3-3f717ef7d5dc",
   "metadata": {},
   "source": [
    "## Reflection on Dr. Gebru's presentation at Hillcrest\n",
    "\n",
    "I was really looking forward to Dr. Gebru's talk- I really enjoyed the lecture Dr. Chodrow had posted to on the assignments page- and am also familiar with some of her other work. I've enjoyed listening to her one of my favorite podcasts- In Machines We Trust- and really liked her paper on stochastic parrots. I was, however, somewhat disappointed by her talk. I am familiar with the ideas espoused by Effective Altruism. I do not agree with these ideas. I think that Effective Altruism's mission is deeply flawed- the idea that a select few wealthy individuals should leverege their wealth to change the world in a manner that they deem fit is undemocratic and dangerous. I also believe that this movement is used by corporations, such as FTX, to put on a facade of doing good whilst obscuring their unethical deeds. However, I think that it is a stretch to dub this movement to be eugenicist. \n",
    "\n",
    "I am not too familiar with the other movements she mentioned- such as transhumanism, extropianism and singulartarianism- however I do not think that she effectively showed how any of the TESCREAL movements are definitionally eugenics. I think that the question that Tim asked in the question and answer session was particularly important. It is important to define what eugenics is to show that certain movements are eugenicist. Her response to that- which was a version of \"go read a book\"- felt inappropriate. An earnest answer to that question was central to the discussion- and hence there was value lost in this interaction. \n",
    "\n",
    "It also felt as though she was cherry picking quotes from cherry picked figures in these movements- and she used sweeping generalizations to argue that these movements are eugenicist. Overall, I was a little disappointed in the lack of nuance in her argument. This could be a result of time constraints. I was really looking forward to this session with Dr. Gebru, am a little disheartened by how it turned out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b62cc96-0f87-4051-9c58-0efc763ffa3a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ml-0451]",
   "language": "python",
   "name": "conda-env-ml-0451-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
